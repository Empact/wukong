h1. Wukong

Wukong makes Hadoop so easy a chimpanzee can use it.

Treat your dataset like a
* stream of lines when it's efficient to process by lines
* stream of field arrays when it's efficient to deal directly with fields
* stream of lightweight objects when it's efficient to deal with objects

Wukong is friends with "Hadoop":http://hadoop.apache.org/core the elephant,
"Pig":http://hadoop.apache.org/pig/ the query language, and the @cat@ on your
command line.

h2. How to write a Wukong script


Here's a script to count words in a text stream:

  require 'wukong'
  module WordCount
    class Mapper < Wukong::Streamer::LineStreamer
      # Emit each word in the line.
      def process line
        words = line.strip.split(/\W+/).reject(&:blank?)
        words.each{|word| yield [word, 1] }
      end
    end

    class Reducer < Wukong::Streamer::ListReducer
      def finalize
        yield [ key, values.map(&:last).map(&:to_i).sum ]
      end
    end
  end

  Wukong::Script.new(
    WordCount::Mapper,
    WordCount::Reducer
    ).run # Execute the script

The first class, the Mapper, eats lines and craps @[word, count]@ records: word
is the /key/, its count is the /value/.

In the reducer, the values for each key are stacked up into a list; then the
record(s) yielded by @#finalize@ are emitted.

h3. Structured data stream

You can also use structs to treat your dataset as a stream of objects:

  require 'wukong'
  require 'my_blog' #defines the blog models
  # structs for our input objects
  Tweet = Struct.new( :id, :created_at, :twitter_user_id,
    :in_reply_to_user_id, :in_reply_to_status_id, :text )
  TwitterUser  = Struct.new( :id, :username, :fullname,
    :homepage, :location, :description )
  module TwitBlog
    class Mapper < Wukong::Streamer::RecordStreamer
      # Watch for tweets by me
      MY_USER_ID = 24601
      #
      # If this is a tweet is by me, convert it to a Post.
      #
      # If it is a tweet not by me, convert it to a Comment that 
      # will be paired with the correct Post.
      #
      # If it is a TwitterUser, convert it to a User record and
      # a user_location record
      #
      def process record
        case record
	when TwitterUser
	  user     = MyBlog::User.new.merge(record) # grab the fields in common
	  user_loc = MyBlog::UserLoc.new(record.id, record.location, nil, nil)
	  yield user
	  yield user_loc
	when Tweet
	  if record.twitter_user_id == MY_USER_ID
	    post = MyBlog::Post.new.merge record
	    post.link = "http://twitter.com/statuses/show/#{record.id}"
	    post.body = record.text
	    post.title = record.text[0..65] + "..."
	    yield post
	  else
   	    comment = MyBlog::Comment.new.merge record
	    comment.body    = record.text
	    comment.post_id = record.in_reply_to_status_id
	    yield comment
	  end
	end
      end
    end
  end
  Wukong::Script.new( TwitBlog::Mapper, nil ).run # identity reducer

h3. More info
    
There are many useful examples (including an actually-useful version of the
WordCount script) in examples/ directory.


h2. How to run a Wukong script

  your/script.rb --go path/to/input_files path/to/output_dir

All of the file paths are HDFS paths except your script path, of course, which
is on the local filesystem.

You can supply arbitrary command line arguments (they wind up as key-value pairs
in the options path your mapper and reducer receive), and you can use the hadoop
syntax to specify more than one input file:

  ./path/to/your/script.rb --any_specific_options --options=can_have_vals \
    --go "input_dir/part_*,input_file2.tsv,etc.tsv" path/to/output_dir


h2. How to test your scripts

To run mapper on its own:

  cat ./local/test/input.tsv | ./examples/word_count.rb --map | more
  
or if your test data lies on the HDFS,

  hdp-cat test/input.tsv | ./examples/word_count.rb --map | more


h2. What's up with Wukong::AndPig?

@Wukong::AndPig@ is a small library to more easily generate code for the
"Pig":http://hadoop.apache.org/pig data analysis language.  See its
"README":wukong/and_pig/README.textile for more.

h2. Why is it called Wukong?

Hadoop, as you may know, is "named after a stuffed
elephant,"http://en.wikipedia.org/wiki/Hadoop and since Wukong was started by
the "infochimps":http://infochimps.org team, we needed a simian analog. Wukong
(the Monkey King), known for his power and agility, is hero of a famous Chinese
Fairytale in which he journeys to the land of the Elephant:

bq. Sun Wukong (孙悟空), known in the West as the Monkey King, is the main
character in the classical Chinese epic novel Journey to the West. In the novel,
he accompanies the monk Xuanzang on the journey to retrieve Buddhist sutras from
India.

bq. Sun Wukong possesses incredible strength, being able to lift his 13,500 jīn
(8,100 kg) Ruyi Jingu Bang with ease. He also has superb speed, traveling
108,000 li (54,000 kilometers) in one somersault. Sun knows 72 transformations,
which allows him to transform into various animals and objects; he is, however,
shown with slight problems transforming into other people, since he is unable to
complete the transformation of his tail. He is a skilled fighter, capable of
holding his own against the best generals of heaven. Each of his hairs possesses
magical properties, and is capable of transforming into a clone of the Monkey
King himself, or various weapons, animals, and other objects. He also knows
various spells in order to command wind, part water, conjure protective circles
against demons, freeze humans, demons, and gods alike. (Journey to the West, Wu
Cheng'en (1500-1582), Translated by Foreign Languages Press, Beijing 1993.) --
/["Sun Wukong's Wikipedia entry":http://en.wikipedia.org/wiki/Wukong]/

p. Sounds about right to us :) The "BBC-produced Jaime Hewlett / Damon Albarn
short,":http://news.bbc.co.uk/sport1/hi/olympics/monkey made for the 2008
Olympics, gives the general idea.

h2. What tools does Wukong work with?

Wukong is friends with "Hadoop":http://hadoop.apache.org/core the elephant,
"Pig":http://hadoop.apache.org/pig/ the query language, and the @cat@ on your
command line.  We're looking forward to being friends with
"martinis":http://datamapper.org and "express
trains":http://wiki.rubyonrails.org/rails/pages/ActiveRecord down the road.
